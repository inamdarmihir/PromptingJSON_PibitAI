{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Write a ChatGPT Prompt which takes your Resume as input and parse the content in JSON format. Share Github Link of the solution if possible.**"
      ],
      "metadata": {
        "id": "h2PGtsE-7f_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2 requests openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc3mr6fr7oiN",
        "outputId": "8cc56a1a-aaca-4a7a-82eb-138e93d0f8e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Environment Credentials and Packages:"
      ],
      "metadata": {
        "id": "TpR68OqXCJEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"ThisIsNotToBeShared123\""
      ],
      "metadata": {
        "id": "DsOGEKhT7cKO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining Prompt for JSON Extraction:"
      ],
      "metadata": {
        "id": "u_jRfCTQCWP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_file_path):\n",
        "    with open(pdf_file_path, \"rb\") as f:\n",
        "        pdf_reader = PyPDF2.PdfReader(f)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "        return text\n",
        "\n",
        "# Function to call ChatGPT with the extracted resume text\n",
        "def parse_resume_with_chatgpt(resume_text):\n",
        "    prompt = f\"\"\"\n",
        "    You are an AI assistant specialized in parsing resumes. Given the text content of a resume, your task is to extract the relevant sections and convert them into a structured JSON format. The sections to extract include:\n",
        "\n",
        "    1. Personal Information (Name, Email, Phone, LinkedIn, GitHub, etc.)\n",
        "    2. Summary\n",
        "    3. Education (Degree, Institution, Graduation Year, etc.)\n",
        "    4. Experience (Job Title, Company, Duration, Responsibilities, etc.)\n",
        "    5. Skills\n",
        "    6. Projects (Title, Description, Technologies, etc.)\n",
        "    7. Certifications (Title, Issuing Organization, Date, etc.)\n",
        "\n",
        "    Example JSON output format:\n",
        "\n",
        "    ```json\n",
        "    {{\n",
        "        \"personal_information\": {{\n",
        "            \"name\": \"\",\n",
        "            \"email\": \"\",\n",
        "            \"phone\": \"\",\n",
        "            \"linkedin\": \"\",\n",
        "            \"github\": \"\"\n",
        "        }},\n",
        "        \"summary\": \"\",\n",
        "        \"education\": [\n",
        "            {{\n",
        "                \"degree\": \"\",\n",
        "                \"institution\": \"\",\n",
        "                \"graduation_year\": \"\"\n",
        "            }}\n",
        "        ],\n",
        "        \"experience\": [\n",
        "            {{\n",
        "                \"job_title\": \"\",\n",
        "                \"company\": \"\",\n",
        "                \"duration\": \"\",\n",
        "                \"responsibilities\": [\n",
        "                    \"\"\n",
        "                ]\n",
        "            }}\n",
        "        ],\n",
        "        \"skills\": [],\n",
        "        \"projects\": [\n",
        "            {{\n",
        "                \"title\": \"\",\n",
        "                \"description\": \"\",\n",
        "                \"technologies\": []\n",
        "            }}\n",
        "        ],\n",
        "        \"certifications\": [\n",
        "            {{\n",
        "                \"title\": \"\",\n",
        "                \"issuing_organization\": \"\",\n",
        "                \"date\": \"\"\n",
        "            }}\n",
        "        ]\n",
        "    }}\n",
        "\n",
        "    Please input the text content of the resume:\n",
        "\n",
        "    {resume_text}\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=2000,\n",
        "        temperature=0.2,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].text.strip()"
      ],
      "metadata": {
        "id": "-VL_Ek11CU6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parsing JSON Data:**"
      ],
      "metadata": {
        "id": "qRkgFx_w72SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example PDF resume file path\n",
        "pdf_file_path = \"/content/Mihir_Inamdar_Resume.pdf\"\n",
        "\n",
        "# Extract text from the PDF resume\n",
        "resume_text = extract_text_from_pdf(pdf_file_path)\n",
        "\n",
        "# Parse the resume using ChatGPT\n",
        "parsed_resume = parse_resume_with_chatgpt(resume_text)\n",
        "parsed_resume_json = json.loads(parsed_resume)\n",
        "\n",
        "# Print the parsed resume in JSON format\n",
        "print(json.dumps(parsed_resume_json, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fLehF1_7lRE",
        "outputId": "fbf04417-370d-4c4d-e3f5-3dec92f7086a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"personal_information\": {\n",
            "    \"name\": \"Mihir Inamdar\",\n",
            "    \"email\": \"mihirsinamdar@outlook.com\",\n",
            "    \"phone\": \"+917447854428\",\n",
            "    \"linkedin\": \"in/inamdarmihir\",\n",
            "    \"github\": \"www.github.com/inamdarmihir\"\n",
            "  },\n",
            "  \"summary\": \"Experienced AI assistant with a strong background in NLP, deep learning, and data science. Skilled in various programming languages and frameworks, with a proven track record of delivering successful projects and achieving high accuracy rates. Strong communication and collaboration skills, with a focus on problem-solving and critical thinking.\",\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"Bachelors of Engineering - Information Technology\",\n",
            "      \"institution\": \"Pune Institute of Computer Technology\",\n",
            "      \"graduation_year\": \"2024\",\n",
            "      \"gpa\": \"7.74\"\n",
            "    }\n",
            "  ],\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"job_title\": \"Graduate Research Fellow\",\n",
            "      \"company\": \"CVIT, IIIT Hyderabad\",\n",
            "      \"duration\": \"March 2024 - July 2024\",\n",
            "      \"responsibilities\": [\n",
            "        \"Achieved a 20% increase in OCR accuracy for low-resolution images by leveraging neural network algorithms and conducting thorough experimental validations with Meta Reality Labs.\",\n",
            "        \"Conducted in-depth comparative analysis between diffusion models and GANs to identify optimal approaches for better prediction accuracy.\",\n",
            "        \"Analyzed images and curated datasets across diverse lighting conditions.\",\n",
            "        \"Jointly supervised by Dr. Ajoy Mondal and Prof. C.V. Jawahar.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"job_title\": \"NLP and Backend Intern\",\n",
            "      \"company\": \"Textify AI\",\n",
            "      \"duration\": \"October 2023 - January 2024\",\n",
            "      \"responsibilities\": [\n",
            "        \"Developed a Full Stack ML-based Ticket Qualification Platform using FastAPI, Langchain, Node.js, and MongoDB.\",\n",
            "        \"Developed a NLP model that analyzed customer support tickets to predict the category and the severity of the ticket. The model was able to achieve a maximum F1-Score of 99.8% and 93.7% respectively.\",\n",
            "        \"Created an efficient and user-friendly platform for the client by implementing the FastAPI framework and the Langchain algorithm, which reduced the number of translation errors by 10% and improved the server's response time by 15%.\",\n",
            "        \"Continuously working on improving the performance and functionality of the system to meet client requirements.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"job_title\": \"LLM Product Intern\",\n",
            "      \"company\": \"Cellstrat AI Hub\",\n",
            "      \"duration\": \"June 2023 - September 2023\",\n",
            "      \"responsibilities\": [\n",
            "        \"Fine-tuned the GPT-2 model on the Llama 2 conversational QA dataset to create a Virtual Assistant Bot which achieved an accuracy of 70% on answering questions about the company's product and services.\",\n",
            "        \"Reduced the conversational AI model's error rate by 10% by collaborating with the team to improve the model's performance and user experience.\",\n",
            "        \"Organized, launched, and ran a series of experiments that improved the effectiveness of the LLM technology.\",\n",
            "        \"Assisted in building and testing dialogue systems and conversational agents to enhance virtual assistant capabilities.\",\n",
            "        \"Achieved a 20% accuracy level improvement across chatbot conversations.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"job_title\": \"Data Science Fellow\",\n",
            "      \"company\": \"Fellowship.ai\",\n",
            "      \"duration\": \"January 2023 - April 2023\",\n",
            "      \"responsibilities\": [\n",
            "        \"Led a finance-based project to design and fine-tune a Language Model (LLM) for expert financial advice using deep learning and NLP techniques, which resulted in the ability to extract company names from financial reports.\",\n",
            "        \"Trained the model on curated financial data, achieving a 5% improvement in accuracy, enabling it to understand user queries, classify them, and provide accurate, detailed, and risk-aware responses.\",\n",
            "        \"Completed a Natural Language Processing project by utilizing Transformers, GPT 3.5, Hugging Face library, wandb, torch, LangChain, Python, pandas, Kaggle, and Colab. Achieved an accuracy score of 0.92.\",\n",
            "        \"Developed Python code to generate Q&A pairs from over 30 websites using OpenAI and Beautiful Soup, addressing rate-limiting issues, achieving a total of 2,000 Q&A pairs.\",\n",
            "        \"Achieved an overall accuracy rate of 96.7%.\"\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"skills\": [\n",
            "    \"R\",\n",
            "    \"Python\",\n",
            "    \"C++\",\n",
            "    \"C\",\n",
            "    \"Golang\",\n",
            "    \"JS\",\n",
            "    \"Node.js\",\n",
            "    \"Django\",\n",
            "    \"Flask\",\n",
            "    \"MongoDB\",\n",
            "    \"MySQL\",\n",
            "    \"Firebase\",\n",
            "    \"Git\",\n",
            "    \"Docker\",\n",
            "    \"Kubernetes\",\n",
            "    \"MATLAB\",\n",
            "    \"Langchain\",\n",
            "    \"LlamaIndex\",\n",
            "    \"PyTorch\",\n",
            "    \"Tensor Flow\",\n",
            "    \"Scikit-learn\",\n",
            "    \"AWS Sagemaker\",\n",
            "    \"Git\",\n",
            "    \"Postman API\",\n",
            "    \"GraphQL\",\n",
            "    \"Problem Solving\",\n",
            "    \"Critical Thinking\",\n",
            "    \"Communication\",\n",
            "    \"Collaboration\",\n",
            "    \"Adaptability\"\n",
            "  ],\n",
            "  \"projects\": [\n",
            "    {\n",
            "      \"title\": \"OCR Accuracy Improvement using Neural Networks\",\n",
            "      \"description\": \"Achieved a 20% increase in OCR accuracy for low-resolution images by leveraging neural network algorithms and conducting thorough experimental validations with Meta Reality Labs.\",\n",
            "      \"technologies\": [\n",
            "        \"Neural Networks\",\n",
            "        \"OCR\",\n",
            "        \"Meta Reality Labs\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Ticket Qualification Platform\",\n",
            "      \"description\": \"Developed a Full Stack ML-based Ticket Qualification Platform using FastAPI, Langchain, Node.js, and MongoDB.\",\n",
            "      \"technologies\": [\n",
            "        \"FastAPI\",\n",
            "        \"Langchain\",\n",
            "        \"Node.js\",\n",
            "        \"MongoDB\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"NLP Model for Customer Support Tickets\",\n",
            "      \"description\": \"Developed a NLP model that analyzed customer support tickets to predict the category and the severity of the ticket. The model was able to achieve a maximum F1-Score of 99.8% and 93.7% respectively.\",\n",
            "      \"technologies\": [\n",
            "        \"NLP\",\n",
            "        \"FastAPI\",\n",
            "        \"Langchain\",\n",
            "        \"Node.js\",\n",
            "        \"MongoDB\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Virtual Assistant Bot\",\n",
            "      \"description\": \"Fine-tuned the GPT-2 model on the Llama 2 conversational QA dataset to create a Virtual Assistant Bot which achieved an accuracy of 70% on answering questions about the company's product and services.\",\n",
            "      \"technologies\": [\n",
            "        \"GPT-2\",\n",
            "        \"Llama 2\",\n",
            "        \"Conversational QA\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Finance-based Language Model\",\n",
            "      \"description\": \"Designed and fine-tuned a Language Model (LLM) for expert financial advice using deep learning and NLP techniques, which resulted in the ability to extract company names from financial reports.\",\n",
            "      \"technologies\": [\n",
            "        \"LLM\",\n",
            "        \"Deep Learning\",\n",
            "        \"NLP\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Q&A Generation from Websites\",\n",
            "      \"description\": \"Developed Python code to generate Q&A pairs from over 30 websites using OpenAI and Beautiful Soup, addressing rate-limiting issues, achieving a total of 2,000 Q&A pairs.\",\n",
            "      \"technologies\": [\n",
            "        \"Python\",\n",
            "        \"OpenAI\",\n",
            "        \"Beautiful Soup\"\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"certifications\": [\n",
            "    {\n",
            "      \"title\": \"On Importance of Code-Mixed Embeddings for Hate Speech Identification\",\n",
            "      \"issuing_organization\": \"Manchester Metropolitan University, UK\",\n",
            "      \"date\": \"July 2024\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Enhancing Code-Mixing in Named Entity Recognition: A Comprehensive Survey of Deep Learning Models\",\n",
            "      \"issuing_organization\": \"VIT, Vellore, TN, India\",\n",
            "      \"date\": \"February 2024\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}